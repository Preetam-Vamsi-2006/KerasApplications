{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3fb29c",
   "metadata": {},
   "source": [
    "# Keras Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffb3cd",
   "metadata": {},
   "source": [
    "## RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd74a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import array_to_img,img_to_array,load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77357664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Predictions:\n",
      "1. tiger: 83.53%\n",
      "2. tiger_cat: 16.16%\n",
      "3. jaguar: 0.23%\n",
      "Top predicted class index: 292\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\bengaltiger.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array) \n",
    "\n",
    "#Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "#Decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e237c",
   "metadata": {},
   "source": [
    "## ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f49324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102869336/102869336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Predictions:\n",
      "1. tiger: 92.02%\n",
      "2. tiger_cat: 7.94%\n",
      "3. jaguar: 0.02%\n",
      "Top predicted class index: 292\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50V2(weights='imagenet')\n",
    "\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\bengaltiger.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array) \n",
    "\n",
    "#Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "#Decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00802d4b",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8159c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
      "Predictions:\n",
      "1. tiger: 82.13%\n",
      "2. tiger_cat: 17.74%\n",
      "3. lynx: 0.05%\n",
      "Top predicted class index: 292\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\bengaltiger.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array) \n",
    "\n",
    "#Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "#Decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c0d90",
   "metadata": {},
   "source": [
    "## Peacock Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104babb3",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f0ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m91884032/91884032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predictions:\n",
      "1. peacock: 92.42%\n",
      "2. black_grouse: 0.53%\n",
      "3. agama: 0.12%\n",
      "4. bustard: 0.10%\n",
      "5. prairie_chicken: 0.08%\n",
      "Top predicted class index: 84\n",
      "Inference time: 2.1120 seconds\n",
      "Model size: 87.40 MB\n",
      "Number of parameters: 22910480\n",
      "Depth of the model: 134\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = Xception(weights='imagenet')\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "#Measure inference time\n",
    "import time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "#decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "#\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)  # Assuming 4 bytes per float32\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the no.of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "depth = len(model.layers)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "print(f\"Depth of the model: {depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3385ecd",
   "metadata": {},
   "source": [
    "## Inception-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3981ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Predictions:\n",
      "1. peacock: 97.92%\n",
      "2. indigo_bunting: 0.03%\n",
      "3. European_gallinule: 0.03%\n",
      "4. tiger_beetle: 0.02%\n",
      "5. leaf_beetle: 0.02%\n",
      "Top predicted class index: 84\n",
      "Inference time: 3.9935 seconds\n",
      "Model size: 90.99 MB\n",
      "Number of parameters: 23851784\n",
      "Depth of the model: 313\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import  preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = InceptionV3(weights='imagenet')\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "#Measure inference time\n",
    "import time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "#decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "#\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)  # Assuming 4 bytes per float32\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the no.of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "depth = len(model.layers)\n",
    "\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "print(f\"Depth of the model: {depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b6c70",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cefd9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predictions:\n",
      "1. peacock: 98.41%\n",
      "2. limpkin: 0.07%\n",
      "3. black_stork: 0.04%\n",
      "4. coucal: 0.03%\n",
      "5. prairie_chicken: 0.02%\n",
      "Top predicted class index: 84\n",
      "Inference time: 2.1575 seconds\n",
      "Model size: 13.50 MB\n",
      "Number of parameters: 3538984\n",
      "Depth of the model: 156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = MobileNetV2(weights='imagenet')\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "#Measure inference time\n",
    "import time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "#decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "#\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)  # Assuming 4 bytes per float32\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the no.of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "depth = len(model.layers)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "print(f\"Depth of the model: {depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba2616",
   "metadata": {},
   "source": [
    "## DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1bf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m33188688/33188688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "Predictions:\n",
      "1. peacock: 99.94%\n",
      "2. lakeside: 0.01%\n",
      "3. pineapple: 0.00%\n",
      "4. cock: 0.00%\n",
      "5. drake: 0.00%\n",
      "Top predicted class index: 84\n",
      "Inference time: 5.8591 seconds\n",
      "Model size: 30.76 MB\n",
      "Number of parameters: 8062504\n",
      "Depth of the model: 429\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = DenseNet121(weights='imagenet')\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "#Measure inference time\n",
    "import time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "#decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "#\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)  # Assuming 4 bytes per float32\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the no.of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "depth = len(model.layers)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "print(f\"Depth of the model: {depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54258c0a",
   "metadata": {},
   "source": [
    "## NASNetMobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9b211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile.h5\n",
      "\u001b[1m24227760/24227760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "Predictions:\n",
      "1. peacock: 93.72%\n",
      "2. ostrich: 0.06%\n",
      "3. guacamole: 0.06%\n",
      "4. umbrella: 0.06%\n",
      "5. patio: 0.05%\n",
      "Top predicted class index: 84\n",
      "Inference time: 9.0571 seconds\n",
      "Model size: 20.32 MB\n",
      "Number of parameters: 5326716\n",
      "Depth of the model: 771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = NASNetMobile(weights='imagenet')\n",
    "img_path = r'C:\\Users\\golla\\Downloads\\peacock.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "#Measure inference time\n",
    "import time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(img_array)\n",
    "end_time = time.time()\n",
    "#decode and print the top 3 predictions\n",
    "decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "print('Predictions:')\n",
    "for i, (imagenet_id, label, prob) in enumerate(decoded_predictions):\n",
    "    print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "    \n",
    "#\n",
    "top_class_index = np.argmax(predictions[0])\n",
    "print(f\"Top predicted class index: {top_class_index}\")\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2)  # Assuming 4 bytes per float32\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")\n",
    "\n",
    "# Get the no.of parameters and depth from the model's layers\n",
    "num_parameters = model.count_params()\n",
    "depth = len(model.layers)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "print(f\"Depth of the model: {depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef09f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
